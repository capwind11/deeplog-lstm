{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data(name):\n",
    "    num_sessions = 0\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with open(name, 'r') as f:\n",
    "        for line in tqdm(f,\"loading data\"):\n",
    "            num_sessions += 1\n",
    "            seq = [0]+list(map(lambda n: n, map(int, line.strip().split())))+[30]\n",
    "            line = tuple(seq)\n",
    "            \n",
    "            for i in range(len(line) - window_size):\n",
    "                inputs.append(line[i:i + window_size])\n",
    "                outputs.append(line[i + window_size])\n",
    "    print('Number of sessions({}): {}'.format(name, num_sessions))\n",
    "    print('Number of seqs({}): {}'.format(name, len(inputs)))\n",
    "    dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_size, num_keys)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, :, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataloader,current_epoch=0,num_epochs=10):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(current_epoch,current_epoch+num_epochs):  # Loop over the dataset multiple times\n",
    "        train_loss = 0\n",
    "        for step, (seq, label) in enumerate(dataloader):\n",
    "            # Forward pass\n",
    "            seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "            label1= seq[:,1:,:].cpu().long()\n",
    "            label2 = label.view(-1,1,1)\n",
    "            label = torch.cat([label1,label2],1).view(-1,window_size)\n",
    "            label = label.reshape(label.size(0)*label.size(1))\n",
    "            output = model(seq)\n",
    "            output = output.reshape(output.size(0)*output.size(1),-1)\n",
    "            loss = criterion(output, label.to(device))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            writer.add_graph(model, seq)\n",
    "        print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, current_epoch+num_epochs, train_loss / total_step))\n",
    "        writer.add_scalar('train_loss', train_loss / total_step, epoch + 1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed_time: {:.3f}s'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 31\n",
    "num_epochs = 300\n",
    "batch_size = 2048\n",
    "input_size = 1\n",
    "model_dir = 'model'\n",
    "log = 'bd_test_total_loss_batch_size={}_epoch={}'.format(str(batch_size), str(num_epochs))\n",
    "num_layers = 2\n",
    "hidden_size = 64\n",
    "window_size = 10\n",
    "file_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 4855it [00:00, 6741.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(data/hdfs_train): 4855\n",
      "Number of seqs(data/hdfs_train): 56285\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "train_dataset = generate_train_data(file_dir+'hdfs_train')\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "writer = SummaryWriter(log_dir='log/' + log)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# Train the model\n",
    "total_step = len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], train_loss: 2.5356\n",
      "Epoch [2/10], train_loss: 1.6723\n",
      "Epoch [3/10], train_loss: 1.1599\n",
      "Epoch [4/10], train_loss: 0.8698\n",
      "Epoch [5/10], train_loss: 0.7130\n",
      "Epoch [6/10], train_loss: 0.6048\n",
      "Epoch [7/10], train_loss: 0.4954\n",
      "Epoch [8/10], train_loss: 0.3651\n",
      "Epoch [9/10], train_loss: 0.2875\n",
      "Epoch [10/10], train_loss: 0.2538\n",
      "elapsed_time: 105.884s\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(model,dataloader,num_epochs=10)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(model.state_dict(), model_dir + '/' + log + '.pt')\n",
    "writer.close()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单检测一下训练的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "测试对下一标签预测准确率: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([25, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 10,  8, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  8, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 10,  8, 10,  8, 25, 25, 10,  8, 25, 30])\n",
      "tensor([22,  2,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 2, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([ 3, 25, 10, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 2,  2,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25, 10,  8, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22,  2,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3,  8, 10,  8, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 10,  8, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 10,  8,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  2,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 10,  8, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25, 20, 24, 17,  4,  5, 15, 25, 25, 20, 30])\n",
      "tensor([ 2, 10,  8, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([ 8, 25, 25,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  2,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([ 3, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3,  2,  2,  3, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25,  2,  3,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3, 10,  8, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([10, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([ 2, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22,  2,  2,  3, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25,  2,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([25,  3,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([ 8,  3,  2,  3, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25,  2,  3,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 10, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([10, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([30,  2,  2,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 2, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([20,  8, 10,  8, 10,  8, 25, 25, 25,  1, 30])\n",
      "tensor([22,  1,  1,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  2,  2,  3, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 2,  8, 10,  8, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25,  8, 10,  8, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  3,  2,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8,  2,  2,  3, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25,  3,  3,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  8,  1,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 2,  3,  1,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  2,  2,  3, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8,  3,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([30,  3,  2,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 2, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([20,  8, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([30, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3,  2,  2,  3, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 2, 25, 10,  8, 10,  8, 25, 10,  8, 25, 30])\n",
      "tensor([25,  8, 10,  8, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([25, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([ 3, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  3,  2,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  8, 10,  8, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3, 25, 25,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([30, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  3,  2,  3, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([22, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([30,  3,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3, 10,  8, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([30, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 10,  8,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 3, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 2, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 1,  3,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  3,  2,  1, 22, 22, 22, 20, 20, 20, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "测试对下一标签预测准确率: 0it [00:02, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22,  2,  2,  3, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20,  3,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8,  2,  3,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([10, 10,  8, 10,  8, 10,  8, 25, 25, 25, 30])\n",
      "tensor([30,  3,  2,  2, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([ 8, 25, 10,  8, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([25, 25, 25, 25, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([10,  2,  1,  1, 22, 22, 22, 20, 20, 20, 30])\n",
      "tensor([20, 10,  8, 10,  8, 25, 25, 10,  8, 25, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-3bd2cd4e602d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#         print(label[i],predicted[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mcorrect\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'对下一标签预测准确率为: '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_of_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "num_of_seq = 0\n",
    "for step, (seq, label) in tqdm(enumerate(dataloader),desc=\"测试对下一标签预测准确率\"):\n",
    "    # Forward pass\n",
    "    seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "    label1= seq[:,1:,:].cpu().long()\n",
    "    label2 = label.view(-1,1,1)\n",
    "    label = torch.cat([label1,label2],1).view(-1,window_size)\n",
    "    label = label.reshape(label.size(0)*label.size(1))\n",
    "    output = model(seq)\n",
    "    output = output.reshape(output.size(0)*output.size(1),-1)\n",
    "    predicted = torch.argsort(output, 1)[:, -3:].cpu()\n",
    "    num_of_seq+=len(label)\n",
    "    for i in range(len(label)):\n",
    "\n",
    "    #     print(label[i],predicted[i])\n",
    "        if label[i] in predicted[i]:\n",
    "    #         print(label[i],predicted[i])\n",
    "            correct+=1   \n",
    "            if label[i] == 30:\n",
    "                print(label[i-10:i+1])\n",
    "print('对下一标签预测准确率为: '+str(correct/num_of_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  4., 21.,  4.,  4., 10.,  8., 10.,  8., 25.,  8., 25., 25., 25.,\n",
      "        22., 22., 22., 20., 20., 20.,  0., 21.,  4.,  4.,  4., 25., 25., 10.,\n",
      "         8., 10., 21.,  4.,  4.,  4., 25., 25., 25., 10.,  8., 10.,  3.,  3.,\n",
      "         3.,  2., 22., 22., 22., 20., 20., 20.,  8., 10.,  8., 25., 25., 25.,\n",
      "        22., 22., 22., 20.,  4., 10.,  8., 10.,  8., 25., 25., 10.,  8., 25.],\n",
      "       device='cuda:0')\n",
      "tensor([ 4, 21,  4,  4, 10,  8, 10,  8, 25, 25, 25, 25, 25, 22, 22, 22, 20, 20,\n",
      "        20, 30, 21,  4,  4,  4, 25, 25, 10,  8, 10,  8,  4,  4,  4, 25, 25, 25,\n",
      "        10,  8, 10,  8,  3,  3,  2, 22, 22, 22, 20, 20, 20, 30, 10,  8, 25, 25,\n",
      "        25, 22, 22, 22, 20, 20, 10,  8, 10,  8, 25, 25, 10,  8, 25,  1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(seq.reshape(1,-1)[0][70:140])\n",
    "print(label.reshape(1,-1)[0][70:140])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清理缓存释放空间 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data(name):\n",
    "    hdfs = set()\n",
    "    # hdfs = []\n",
    "    with open('data/' + name, 'r') as f:\n",
    "        for ln in f.readlines():\n",
    "            ln = [0]+list(map(lambda n: n, map(int, ln.strip().split())))+[30]\n",
    "            ln = ln + [-1] * (window_size + 1 - len(ln))\n",
    "            hdfs.add(tuple(ln))\n",
    "            # hdfs.append(tuple(ln))\n",
    "    session_to_seq = []\n",
    "    seqs = []\n",
    "    labels = []\n",
    "    seq_count = 0\n",
    "    for line in tqdm(hdfs, \"normal:\"):\n",
    "        session = []\n",
    "        for i in range(len(line) - window_size):\n",
    "            seq = line[i:i + window_size]\n",
    "            label = line[i + window_size]\n",
    "            seqs.append(seq)\n",
    "            session.append(seq_count)\n",
    "            labels.append(label)\n",
    "            seq_count += 1\n",
    "        session_to_seq.append(session)\n",
    "    print('Number of sessions({}): {}'.format(name, len(session_to_seq)))\n",
    "    print('Number of seqs({}): {}'.format(name, len(seqs)))\n",
    "    dataset = TensorDataset(torch.tensor(seqs, dtype=torch.float), torch.tensor(labels))\n",
    "\n",
    "    # print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
    "    return session_to_seq, dataset, seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lstm): LSTM(1, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(input_size, hidden_size, num_layers, num_classes)\n",
    "model.load_state_dict(torch.load(model_dir + '/' + log + '.pt'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal:: 100%|████████████████████████████████████████████████████████████████| 14177/14177 [00:00<00:00, 22030.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(hdfs_test_normal): 14177\n",
      "Number of seqs(hdfs_test_normal): 269570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal:: 100%|██████████████████████████████████████████████████████████████████| 4123/4123 [00:00<00:00, 19548.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(hdfs_test_abnormal): 4123\n",
      "Number of seqs(hdfs_test_abnormal): 88410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "test_normal_session, test_normal_dataset, test_normal_seq = generate_test_data('hdfs_test_normal')\n",
    "normal_dataloader = DataLoader(test_normal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_abnormal_session, test_abnormal_dataset,test_abnormal_seq = generate_test_data('hdfs_test_abnormal')\n",
    "abnormal_dataloader = DataLoader(test_abnormal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 快速预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast predict\n",
    "def fast_predict(model,normal_dataloader,abnormal_dataloader):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    num_candidates=5\n",
    "    # Test the model\n",
    "    start_time = time.time()\n",
    "    test_normal_result = []\n",
    "    test_abnormal_result = []\n",
    "    with torch.no_grad():\n",
    "        result = []\n",
    "        with torch.no_grad():\n",
    "            for step, (seq, labels) in tqdm(enumerate(normal_dataloader), desc='normal'):\n",
    "                seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "                output = model(seq).cpu()\n",
    "\n",
    "                predicted = torch.argsort(output[:,-1,:], 1)[:,-num_candidates:]\n",
    "                for i, label in enumerate(labels):\n",
    "                    if label not in predicted[i]:\n",
    "                        test_normal_result.append(True)\n",
    "                    else:\n",
    "                        test_normal_result.append(False)\n",
    "    for session in test_normal_session:\n",
    "        for seq_id in session:\n",
    "            if test_normal_result[seq_id] == True:\n",
    "                FP += 1\n",
    "                break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (seq, labels) in tqdm(enumerate(abnormal_dataloader), desc='normal'):\n",
    "            seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "            output = model(seq).cpu()\n",
    "\n",
    "            predicted = torch.argsort(output[:,-1,:], 1)[:,-num_candidates:]\n",
    "            for i, label in enumerate(labels):\n",
    "                if label not in predicted[i]:\n",
    "                    test_abnormal_result.append(True)\n",
    "                else:\n",
    "                    test_abnormal_result.append(False)\n",
    "        for session in test_abnormal_session:\n",
    "            for seq_id in session:\n",
    "                if test_abnormal_result[seq_id] == True:\n",
    "                    TP += 1\n",
    "                    break\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
    "    # Compute precision, recall and F1-measure\n",
    "    FN = len(test_abnormal_session) - TP\n",
    "    P = 100 * TP / (TP + FP)\n",
    "    R = 100 * TP / (TP + FN)\n",
    "    F1 = 2 * P * R / (P + R)\n",
    "    print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
    "    print('Finished Predicting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal: 27it [00:40,  1.48s/it]\n",
      "normal: 9it [00:12,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 52.979s\n",
      "false positive (FP): 1513, false negative (FN): 31, Precision: 73.006%, Recall: 99.248%, F1-measure: 84.128%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fast_predict(model,normal_dataloader,abnormal_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_seq(start,window_size=10,num_candidates=5):\n",
    "    bg = start.size(1) \n",
    "    for i in range(bg,bg+window_size):\n",
    "#         start = torch.FloatTensor(start)\n",
    "        seq = start.clone().detach().view(-1, i, input_size).to(device)\n",
    "        output = model(seq).cpu()\n",
    "        predicted = torch.argsort(output[-1], 1)[-1, -num_candidates:]\n",
    "        nxt = random.randint(0,num_candidates-1)\n",
    "        start = torch.cat([start,predicted[nxt].reshape(1,-1).float()],1)\n",
    "    return start,predicted,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(start,window_size=10,num_candidates=5):\n",
    "    bg = start.size(1) \n",
    "    for i in range(bg,bg+window_size):\n",
    "#         start = torch.FloatTensor(start)\n",
    "        seq = start.clone().detach().view(-1, i, input_size).to(device)\n",
    "        output = model(seq).cpu()[:,-1,:]\n",
    "        output = output.reshape(-1)\n",
    "        predicted = torch.argsort(output)[-num_candidates:]\n",
    "        nxt = random.randint(0,num_candidates-1)\n",
    "        start = torch.cat([start,predicted[nxt].reshape(1,-1).float()],1)\n",
    "    return start,predicted,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.FloatTensor([0,1]).reshape(1,-1)\n",
    "t,predicted,output = generate_seq(t,1,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3170e-08, 9.2716e-05, 2.3222e-04, 1.1103e-04, 7.3306e-01, 4.2008e-05,\n",
      "        2.2293e-08, 2.1097e-08, 3.2225e-05, 2.1193e-08, 2.9007e-04, 2.3265e-08,\n",
      "        2.2084e-08, 2.4458e-08, 2.2978e-08, 4.1722e-05, 2.3293e-08, 6.9324e-05,\n",
      "        2.5993e-08, 2.2954e-08, 4.8183e-05, 2.6592e-01, 1.2300e-05, 2.1440e-08,\n",
      "        4.2136e-05, 1.0084e-05, 2.1850e-08, 2.1220e-08, 2.2338e-08, 2.5002e-08,\n",
      "        3.0127e-07], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "prob = softmax(output.reshape(-1))\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  4 21  4  8]\n",
      "预测的序号排序: tensor([ 8, 10,  4])\n",
      "对应的可能性: tensor([1.9306e-04, 3.0414e-03, 9.9664e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8]\n",
      "预测的序号排序: tensor([ 8, 25, 10])\n",
      "对应的可能性: tensor([0.1988, 0.2978, 0.4863], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25]\n",
      "预测的序号排序: tensor([ 8, 25, 10])\n",
      "对应的可能性: tensor([0.0050, 0.4196, 0.5752], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25]\n",
      "预测的序号排序: tensor([ 8, 25, 10])\n",
      "对应的可能性: tensor([0.0015, 0.1662, 0.8322], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10]\n",
      "预测的序号排序: tensor([ 8, 25, 10])\n",
      "对应的可能性: tensor([0.0067, 0.2272, 0.7661], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25]\n",
      "预测的序号排序: tensor([25, 10,  8])\n",
      "对应的可能性: tensor([0.0011, 0.1003, 0.8986], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10]\n",
      "预测的序号排序: tensor([25,  8, 10])\n",
      "对应的可能性: tensor([8.8978e-04, 1.2369e-02, 9.8655e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8]\n",
      "预测的序号排序: tensor([ 3,  8, 10])\n",
      "对应的可能性: tensor([6.0998e-04, 9.5934e-02, 9.0262e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10]\n",
      "预测的序号排序: tensor([25,  8, 10])\n",
      "对应的可能性: tensor([5.7113e-04, 1.2986e-03, 9.9777e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25]\n",
      "预测的序号排序: tensor([25,  8, 10])\n",
      "对应的可能性: tensor([0.0148, 0.2811, 0.6757], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22]\n",
      "预测的序号排序: tensor([ 3, 10, 22])\n",
      "对应的可能性: tensor([0.0423, 0.0498, 0.8507], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22]\n",
      "预测的序号排序: tensor([ 3, 20, 22])\n",
      "对应的可能性: tensor([0.0313, 0.3713, 0.5846], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3]\n",
      "预测的序号排序: tensor([ 3, 22, 20])\n",
      "对应的可能性: tensor([9.2803e-06, 1.2552e-05, 9.9997e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2]\n",
      "预测的序号排序: tensor([ 2,  3, 20])\n",
      "对应的可能性: tensor([0.0075, 0.0440, 0.9410], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3]\n",
      "预测的序号排序: tensor([30,  3, 20])\n",
      "对应的可能性: tensor([0.0233, 0.2070, 0.7678], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3]\n",
      "预测的序号排序: tensor([20,  3, 30])\n",
      "对应的可能性: tensor([0.0781, 0.0915, 0.8111], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3]\n",
      "预测的序号排序: tensor([30,  2,  3])\n",
      "对应的可能性: tensor([0.0322, 0.1878, 0.7402], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2]\n",
      "预测的序号排序: tensor([30,  2,  3])\n",
      "对应的可能性: tensor([0.0279, 0.1707, 0.7990], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1]\n",
      "预测的序号排序: tensor([ 1, 22, 30])\n",
      "对应的可能性: tensor([0.0713, 0.1572, 0.6804], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1]\n",
      "预测的序号排序: tensor([ 1, 30, 22])\n",
      "对应的可能性: tensor([0.2024, 0.2492, 0.5080], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22]\n",
      "预测的序号排序: tensor([ 1, 30, 22])\n",
      "对应的可能性: tensor([0.0656, 0.0667, 0.8629], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1]\n",
      "预测的序号排序: tensor([ 1, 30, 22])\n",
      "对应的可能性: tensor([0.0072, 0.0075, 0.9810], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3]\n",
      "预测的序号排序: tensor([ 1,  3, 22])\n",
      "对应的可能性: tensor([0.1334, 0.2461, 0.4025], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2]\n",
      "预测的序号排序: tensor([1, 2, 3])\n",
      "对应的可能性: tensor([0.0034, 0.1227, 0.8737], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2  1]\n",
      "预测的序号排序: tensor([1, 2, 3])\n",
      "对应的可能性: tensor([2.0817e-04, 1.1249e-02, 9.8851e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2  1  2]\n",
      "预测的序号排序: tensor([3, 2, 1])\n",
      "对应的可能性: tensor([0.1636, 0.2240, 0.5767], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2  1  2 22]\n",
      "预测的序号排序: tensor([ 1, 22,  2])\n",
      "对应的可能性: tensor([0.1687, 0.3424, 0.4415], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2  1  2 22  2]\n",
      "预测的序号排序: tensor([ 2, 17, 22])\n",
      "对应的可能性: tensor([8.7431e-04, 2.4598e-03, 9.9617e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2  1  2 22  2 22]\n",
      "预测的序号排序: tensor([ 3, 22,  2])\n",
      "对应的可能性: tensor([0.0119, 0.0220, 0.9623], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2  1  2 22  2 22 22]\n",
      "预测的序号排序: tensor([ 2, 24, 22])\n",
      "对应的可能性: tensor([0.0016, 0.0017, 0.9960], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2  1  2 22  2 22 22 22]\n",
      "预测的序号排序: tensor([20,  3, 22])\n",
      "对应的可能性: tensor([0.0115, 0.0181, 0.9646], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2  1  2 22  2 22 22 22 30]\n",
      "预测的序号排序: tensor([30,  3, 20])\n",
      "对应的可能性: tensor([5.0409e-05, 3.8199e-04, 9.9944e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  4 21  4  8  8 25 25 10 25 10  8 10 25 22 22  3  2  3  3  3  2  1  1\n",
      " 22  1  3  2  1  2 22  2 22 22 22 30]\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([0,4,21,4]).reshape(1,-1)\n",
    "max_len = 60\n",
    "while t.size(1)<max_len:\n",
    "    t,predicted,output = generate_seq(t,1,3)\n",
    "    prob = softmax(output)\n",
    "    print(t.int().cpu().numpy()[0])\n",
    "    print(\"预测的序号排序:\",end=' ')\n",
    "    print(predicted)\n",
    "    print(\"对应的可能性:\",end=' ')\n",
    "    print(prob[predicted])\n",
    "    print()\n",
    "    if 30 in t[0]:\n",
    "        break\n",
    "print(t.int().cpu().numpy()[0])\n",
    "pattern.add(tuple(t.int().cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9, 27, 23, 26, 12,  6, 28, 19, 14,  0, 11, 16, 13, 29, 18, 30, 25, 22,\n",
      "         8, 15,  5, 24, 20, 17,  1,  3,  2, 10, 21,  4])\n"
     ]
    }
   ],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1193e-08, 2.1220e-08, 2.1440e-08, 2.1850e-08, 2.2084e-08, 2.2293e-08,\n",
       "        2.2338e-08, 2.2954e-08, 2.2978e-08, 2.3170e-08, 2.3265e-08, 2.3293e-08,\n",
       "        2.4458e-08, 2.5002e-08, 2.5993e-08, 3.0127e-07, 1.0084e-05, 1.2300e-05,\n",
       "        3.2225e-05, 4.1722e-05, 4.2008e-05, 4.2136e-05, 4.8183e-05, 6.9324e-05,\n",
       "        9.2716e-05, 1.1103e-04, 2.3222e-04, 2.9007e-04, 2.6592e-01, 7.3306e-01],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[predicted.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 21  4 35 66 35 35 35 35 35 66 35 35 35 35 66 66 66 66 66 35 66 66 35\n",
      " 66 66 35 66 35 66 35 66 66 35 66 66 66 66 66 35 35 35 66 66 66 66 35 35\n",
      " 66 35 66 35 35 35 66 66 35 66 66 35]\n",
      "[  0  21  35  35   4  35  35  35   4 258  35  35  35  35  35  35 258  35\n",
      "  35 258  35 258 258  35  35  35  35  35 258 258 258 258  35 258  35  35\n",
      " 258  35 258 258  35 258  35  35  35  35 258 258  35 258  35  35 258  35\n",
      " 258  35 258 258  35 258]\n",
      "[ 0  4 52 35 52 35 52 35 52 35 35 52 35 35 52 52 52 35 35 52 35 52 52 52\n",
      " 35 52 35 35 35 35 35 35 52 35 52 35 35 35 35 52 35 52 52 52 52 35 35 52\n",
      " 52 35 52 52 52 35 35 52 52 35 52 52]\n",
      "[ 0  4 52 52 35 52 35 52 35 52 35 52 52 52 52 52 52 35 35 52 52 52 52 35\n",
      " 52 52 52 35 35 52 52 52 52 35 52 35 35 52 52 52 52 52 35 35 52 35 35 35\n",
      " 52 52 52 35 52 52 35 52 52 35 52 52]\n",
      "[ 0 21 35  4 97 97 97 97 35 35 35 35 97 35 35 97 35 35 97 35 97 35 35 97\n",
      " 97 97 35 35 35 35 97 35 97 35 97 97 97 35 97 35 97 97 35 97 35 35 97 97\n",
      " 35 97 97 97 35 97 97 97 35 35 35 97]\n",
      "[ 0  4 52 52 52 35 35 35 52 52 35 52 35 52 52 35 35 35 35 35 52 52 35 52\n",
      " 52 35 35 52 35 52 52 35 35 35 35 35 35 52 52 35 35 52 52 52 52 52 52 35\n",
      " 35 35 35 35 35 35 52 52 35 52 35 35]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-239-dae8f7393955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmax_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;36m30\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-232-7992486e909f>\u001b[0m in \u001b[0;36mgenerate_seq\u001b[1;34m(start, window_size, num_candidates)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#         start = torch.FloatTensor(start)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnum_candidates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mnxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_candidates\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-b3bc2642b8cf>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mc0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pattern = set()\n",
    "for i in range(100):\n",
    "    t = torch.FloatTensor([0]).reshape(1,-1)\n",
    "    max_len = 60\n",
    "    while t.size(1)<max_len:\n",
    "        t,predicted,output = generate_seq(t,1,2)\n",
    "        if 30 in t[0]:\n",
    "            break\n",
    "    print(t.int().cpu().numpy()[0])\n",
    "    pattern.add(tuple(t.int().cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 10.,  8., 10.,  8.,  1.,  2.,  2.,  3.,  2.])\n",
      "tensor([[ 8.,  8., 25.,  2.,  2., 22.,  1., 22.,  1.,  1.,  3.]])\n",
      "tensor([10.,  8., 10.,  8.,  1.,  2.,  2.,  3.,  2.])\n",
      "tensor([ 8., 25.,  2.,  2., 22.,  1., 22.,  1.,  1.,  3.])\n",
      "\n",
      "tensor([10.,  8., 10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.])\n",
      "tensor([[10.,  3.,  1.,  3.,  3., 22., 22., 24., 22.,  5.,  5.]])\n",
      "tensor([ 8., 10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.])\n",
      "tensor([ 3.,  1.,  3.,  3., 22., 22., 24., 22.,  5.,  5.])\n",
      "\n",
      "tensor([ 8., 10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.,  2.])\n",
      "tensor([[ 8.,  2.,  2.,  3.,  2.,  3.,  1., 21.,  1., 22.,  2.]])\n",
      "tensor([10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.,  2.])\n",
      "tensor([ 2.,  2.,  3.,  2.,  3.,  1., 21.,  1., 22.,  2.])\n",
      "\n",
      "tensor([10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.,  2.,  2.])\n",
      "tensor([[10.,  8.,  2., 22., 25., 20., 22., 30., 30., 20., 30.]])\n",
      "tensor([8., 1., 2., 2., 3., 2., 3., 2., 2.])\n",
      "tensor([ 8.,  2., 22., 25., 20., 22., 30., 30., 20., 30.])\n",
      "\n",
      "tensor([8., 1., 2., 2., 3., 2., 3., 2., 2., 2.])\n",
      "tensor([[ 8., 25., 10.,  1.,  1.,  1., 22., 22., 22., 22.,  3.]])\n",
      "tensor([1., 2., 2., 3., 2., 3., 2., 2., 2.])\n",
      "tensor([25., 10.,  1.,  1.,  1., 22., 22., 22., 22.,  3.])\n",
      "\n",
      "tensor([1., 2., 2., 3., 2., 3., 2., 2., 2., 3.])\n",
      "tensor([[ 1., 21.,  3.,  5., 15., 22., 10.,  2.,  1.,  1., 22.]])\n",
      "tensor([2., 2., 3., 2., 3., 2., 2., 2., 3.])\n",
      "tensor([21.,  3.,  5., 15., 22., 10.,  2.,  1.,  1., 22.])\n",
      "\n",
      "tensor([2., 2., 3., 2., 3., 2., 2., 2., 3., 1.])\n",
      "tensor([[ 2., 21.,  3.,  1., 22., 24., 20., 22., 20., 20., 24.]])\n",
      "tensor([2., 3., 2., 3., 2., 2., 2., 3., 1.])\n",
      "tensor([21.,  3.,  1., 22., 24., 20., 22., 20., 20., 24.])\n",
      "\n",
      "tensor([ 2.,  3.,  2.,  3.,  2.,  2.,  2.,  3.,  1., 22.])\n",
      "tensor([[ 2., 10.,  2., 10.,  1., 22., 24., 22.,  3., 15.,  5.]])\n",
      "tensor([ 3.,  2.,  3.,  2.,  2.,  2.,  3.,  1., 22.])\n",
      "tensor([10.,  2., 10.,  1., 22., 24., 22.,  3., 15.,  5.])\n",
      "\n",
      "tensor([ 3.,  2.,  3.,  2.,  2.,  2.,  3.,  1., 22., 22.])\n",
      "tensor([[ 3.,  3.,  2.,  2.,  2.,  3.,  2.,  3., 22., 22., 24.]])\n",
      "tensor([ 2.,  3.,  2.,  2.,  2.,  3.,  1., 22., 22.])\n",
      "tensor([ 3.,  2.,  2.,  2.,  3.,  2.,  3., 22., 22., 24.])\n",
      "\n",
      "tensor([ 2.,  3.,  2.,  2.,  2.,  3.,  1., 22., 22., 22.])\n",
      "tensor([[ 2.,  3.,  1.,  1.,  2.,  1., 22., 22.,  2., 20., 30.]])\n",
      "tensor([ 3.,  2.,  2.,  2.,  3.,  1., 22., 22., 22.])\n",
      "tensor([ 3.,  1.,  1.,  2.,  1., 22., 22.,  2., 20., 30.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for step, (seq, labels) in tqdm(enumerate(normal_dataloader), desc='normal'):\n",
    "        break\n",
    "for s in seq[100:110]:\n",
    "    t = s[:1].reshape(1,-1)\n",
    "    res,_ = generate_seq(t)\n",
    "    print(s)\n",
    "    print(res)\n",
    "\n",
    "    print(s[t.size(1):])\n",
    "    print(res[0,t.size(1):])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('cuda_pytorch': conda)",
   "language": "python",
   "name": "python36764bitcudapytorchconda3e33319a1fef4dc990a9d2f171216946"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
