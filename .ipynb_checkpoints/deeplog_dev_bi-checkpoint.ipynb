{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data(name):\n",
    "    num_sessions = 0\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with open(name, 'r') as f:\n",
    "        for line in tqdm(f,\"loading data\"):\n",
    "            num_sessions += 1\n",
    "            seq = [0]+list(map(lambda n: n, map(int, line.strip().split())))+[30]\n",
    "            line = tuple(seq)\n",
    "            \n",
    "            for i in range(len(line) - window_size):\n",
    "                inputs.append(line[i:i + window_size])\n",
    "                outputs.append(line[i + window_size])\n",
    "    print('Number of sessions({}): {}'.format(name, num_sessions))\n",
    "    print('Number of seqs({}): {}'.format(name, len(inputs)))\n",
    "    dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_size, num_keys)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, :, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataloader,current_epoch=0,num_epochs=10):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(current_epoch,current_epoch+num_epochs):  # Loop over the dataset multiple times\n",
    "        train_loss = 0\n",
    "        for step, (seq, label) in enumerate(dataloader):\n",
    "            # Forward pass\n",
    "            seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "            label1= seq[:,1:,:].cpu().long()\n",
    "            label2 = label.view(-1,1,1)\n",
    "            label = torch.cat([label1,label2],1).view(-1,window_size)\n",
    "            label = label.reshape(label.size(0)*label.size(1))\n",
    "            output = model(seq)\n",
    "            output = output.reshape(output.size(0)*output.size(1),-1)\n",
    "            loss = criterion(output, label.to(device))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            writer.add_graph(model, seq)\n",
    "        print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, current_epoch+num_epochs, train_loss / total_step))\n",
    "        writer.add_scalar('train_loss', train_loss / total_step, epoch + 1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed_time: {:.3f}s'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 31\n",
    "num_epochs = 300\n",
    "batch_size = 2048\n",
    "window_size = 5\n",
    "input_size = 1\n",
    "model_dir = 'model'\n",
    "log = 'bd_test_total_loss_batch_size={}_epoch={}_window_size={}'.format(str(batch_size), str(num_epochs),str(window_size))\n",
    "num_layers = 2\n",
    "hidden_size = 64\n",
    "\n",
    "file_dir = 'data/'\n",
    "model = Model(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重新训练\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if os.path.exists(model_dir + '/' + log + '.pt'):\n",
    "    model.load_state_dict(torch.load(model_dir + '/' + log + '.pt'))\n",
    "    print(\"成功加载模型\"+model_dir + '/' + log + '.pt')\n",
    "else:\n",
    "    print(\"重新训练\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 4855it [00:00, 9928.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(data/hdfs_train): 4855\n",
      "Number of seqs(data/hdfs_train): 80560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = generate_train_data(file_dir+'hdfs_train')\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "writer = SummaryWriter(log_dir='log/' + log)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# Train the model\n",
    "total_step = len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  5.,  5.,  5., 22.]), tensor(11))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/60], train_loss: 1.3704\n",
      "Epoch [12/60], train_loss: 0.9560\n",
      "Epoch [13/60], train_loss: 0.6861\n",
      "Epoch [14/60], train_loss: 0.4707\n",
      "Epoch [15/60], train_loss: 0.3396\n",
      "Epoch [16/60], train_loss: 0.2786\n",
      "Epoch [17/60], train_loss: 0.2365\n",
      "Epoch [18/60], train_loss: 0.2044\n",
      "Epoch [19/60], train_loss: 0.1806\n",
      "Epoch [20/60], train_loss: 0.1641\n",
      "Epoch [21/60], train_loss: 0.1518\n",
      "Epoch [22/60], train_loss: 0.1407\n",
      "Epoch [23/60], train_loss: 0.1327\n",
      "Epoch [24/60], train_loss: 0.1258\n",
      "Epoch [25/60], train_loss: 0.1197\n",
      "Epoch [26/60], train_loss: 0.1151\n",
      "Epoch [27/60], train_loss: 0.1109\n",
      "Epoch [28/60], train_loss: 0.1092\n",
      "Epoch [29/60], train_loss: 0.1551\n",
      "Epoch [30/60], train_loss: 0.1061\n",
      "Epoch [31/60], train_loss: 0.1014\n",
      "Epoch [32/60], train_loss: 0.0989\n",
      "Epoch [33/60], train_loss: 0.0969\n",
      "Epoch [34/60], train_loss: 0.0952\n",
      "Epoch [35/60], train_loss: 0.0936\n",
      "Epoch [36/60], train_loss: 0.0921\n",
      "Epoch [37/60], train_loss: 0.0908\n",
      "Epoch [38/60], train_loss: 0.0896\n",
      "Epoch [39/60], train_loss: 0.0887\n",
      "Epoch [40/60], train_loss: 0.0870\n",
      "Epoch [41/60], train_loss: 0.0866\n",
      "Epoch [42/60], train_loss: 0.0853\n",
      "Epoch [43/60], train_loss: 0.0848\n",
      "Epoch [44/60], train_loss: 0.0840\n",
      "Epoch [45/60], train_loss: 0.0837\n",
      "Epoch [46/60], train_loss: 0.0822\n",
      "Epoch [47/60], train_loss: 0.0819\n",
      "Epoch [48/60], train_loss: 0.0811\n",
      "Epoch [49/60], train_loss: 0.0805\n",
      "Epoch [50/60], train_loss: 0.0799\n",
      "Epoch [51/60], train_loss: 0.0798\n",
      "Epoch [52/60], train_loss: 0.0791\n",
      "Epoch [53/60], train_loss: 0.0784\n",
      "Epoch [54/60], train_loss: 0.0779\n",
      "Epoch [55/60], train_loss: 0.0779\n",
      "Epoch [56/60], train_loss: 0.0771\n",
      "Epoch [57/60], train_loss: 0.0771\n",
      "Epoch [58/60], train_loss: 0.0766\n",
      "Epoch [59/60], train_loss: 0.0761\n",
      "Epoch [60/60], train_loss: 0.0757\n",
      "elapsed_time: 625.289s\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(model,dataloader,current_epoch=10,num_epochs=50)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(model.state_dict(), model_dir + '/' + log + '.pt')\n",
    "writer.close()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(model.state_dict(), model_dir + '/' + log + '.pt')\n",
    "writer.close()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单检测一下训练的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "测试对下一标签预测准确率: 40it [00:43,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对下一标签预测准确率为: 0.995759682224429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "num_of_seq = 0\n",
    "for step, (seq, label) in tqdm(enumerate(dataloader),desc=\"测试对下一标签预测准确率\"):\n",
    "    # Forward pass\n",
    "    seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "    label1= seq[:,1:,:].cpu().long()\n",
    "    label2 = label.view(-1,1,1)\n",
    "    label = torch.cat([label1,label2],1).view(-1,window_size)\n",
    "    label = label.reshape(label.size(0)*label.size(1))\n",
    "    output = model(seq)\n",
    "    output = output.reshape(output.size(0)*output.size(1),-1)\n",
    "    predicted = torch.argsort(output, 1)[:, -3:].cpu()\n",
    "    num_of_seq+=len(label)\n",
    "    for i in range(len(label)):\n",
    "\n",
    "    #     print(label[i],predicted[i])\n",
    "        if label[i] in predicted[i]:\n",
    "    #         print(label[i],predicted[i])\n",
    "            correct+=1   \n",
    "#             if label[i] == 30:\n",
    "#                 print(label[i-10:i+1])\n",
    "print('对下一标签预测准确率为: '+str(correct/num_of_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  4., 21.,  4.,  4., 10.,  8., 10.,  8., 25.,  8., 25., 25., 25.,\n",
      "        22., 22., 22., 20., 20., 20.,  0., 21.,  4.,  4.,  4., 25., 25., 10.,\n",
      "         8., 10., 21.,  4.,  4.,  4., 25., 25., 25., 10.,  8., 10.,  3.,  3.,\n",
      "         3.,  2., 22., 22., 22., 20., 20., 20.,  8., 10.,  8., 25., 25., 25.,\n",
      "        22., 22., 22., 20.,  4., 10.,  8., 10.,  8., 25., 25., 10.,  8., 25.],\n",
      "       device='cuda:0')\n",
      "tensor([ 4, 21,  4,  4, 10,  8, 10,  8, 25, 25, 25, 25, 25, 22, 22, 22, 20, 20,\n",
      "        20, 30, 21,  4,  4,  4, 25, 25, 10,  8, 10,  8,  4,  4,  4, 25, 25, 25,\n",
      "        10,  8, 10,  8,  3,  3,  2, 22, 22, 22, 20, 20, 20, 30, 10,  8, 25, 25,\n",
      "        25, 22, 22, 22, 20, 20, 10,  8, 10,  8, 25, 25, 10,  8, 25,  1])\n"
     ]
    }
   ],
   "source": [
    "print(seq.reshape(1,-1)[0][70:140])\n",
    "print(label.reshape(1,-1)[0][70:140])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清理缓存释放空间 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data(name,window_size=10):\n",
    "    hdfs = set()\n",
    "    # hdfs = []\n",
    "    with open('data/' + name, 'r') as f:\n",
    "        for ln in f.readlines():\n",
    "            ln = [0]+list(map(lambda n: n, map(int, ln.strip().split())))+[30]\n",
    "            ln = ln + [-1] * (window_size + 1 - len(ln))\n",
    "            hdfs.add(tuple(ln))\n",
    "            # hdfs.append(tuple(ln))\n",
    "    session_to_seq = []\n",
    "    seqs = []\n",
    "    labels = []\n",
    "    seq_count = 0\n",
    "    for line in tqdm(hdfs, \"normal:\"):\n",
    "        session = []\n",
    "        for i in range(len(line) - window_size):\n",
    "            seq = line[i:i + window_size]\n",
    "            label = line[i + window_size]\n",
    "            seqs.append(seq)\n",
    "            session.append(seq_count)\n",
    "            labels.append(label)\n",
    "            seq_count += 1\n",
    "        session_to_seq.append(session)\n",
    "    print('Number of sessions({}): {}'.format(name, len(session_to_seq)))\n",
    "    print('Number of seqs({}): {}'.format(name, len(seqs)))\n",
    "    dataset = TensorDataset(torch.tensor(seqs, dtype=torch.float), torch.tensor(labels))\n",
    "\n",
    "    # print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
    "    return session_to_seq, dataset, seqs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lstm): LSTM(1, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(input_size, hidden_size, num_layers, num_classes)\n",
    "model.load_state_dict(torch.load(model_dir + '/' + log + '.pt'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal:: 100%|████████████████████████████████████████████████████████████████| 14177/14177 [00:01<00:00, 13400.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(hdfs_test_normal): 14177\n",
      "Number of seqs(hdfs_test_normal): 269570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal:: 100%|██████████████████████████████████████████████████████████████████| 4123/4123 [00:00<00:00, 22778.41it/s]\n",
      "normal: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(hdfs_test_abnormal): 4123\n",
      "Number of seqs(hdfs_test_abnormal): 88410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal: 27it [00:40,  1.50s/it]\n",
      "abnormal: 9it [00:13,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 53.588s\n",
      "false positive (FP): 654, false negative (FN): 92, Precision: 86.041%, Recall: 97.769%, F1-measure: 91.530%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "batch_size = 10000\n",
    "window_size = 10\n",
    "test_normal_session, test_normal_dataset, test_normal_seq,test_normal_label = generate_test_data('hdfs_test_normal',window_size)\n",
    "normal_dataloader = DataLoader(test_normal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_abnormal_session, test_abnormal_dataset,test_abnormal_seq,test_abnormal_label = generate_test_data('hdfs_test_abnormal',window_size)\n",
    "abnormal_dataloader = DataLoader(test_abnormal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "test_normal_result,test_abnormal_result = fast_predict(model,normal_dataloader,abnormal_dataloader,10,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal:: 100%|████████████████████████████████████████████████████████████████| 14177/14177 [00:00<00:00, 25271.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(hdfs_test_normal): 14177\n",
      "Number of seqs(hdfs_test_normal): 340455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal:: 100%|██████████████████████████████████████████████████████████████████| 4123/4123 [00:00<00:00, 27493.86it/s]\n",
      "normal: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(hdfs_test_abnormal): 4123\n",
      "Number of seqs(hdfs_test_abnormal): 108981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal: 35it [00:39,  1.12s/it]\n",
      "abnormal: 11it [00:12,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 51.352s\n",
      "false positive (FP): 1541, false negative (FN): 359, Precision: 70.952%, Recall: 91.293%, F1-measure: 79.847%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "window_size = 5\n",
    "test_normal_session, test_normal_dataset, test_normal_seq,test_normal_label = generate_test_data('hdfs_test_normal',window_size)\n",
    "normal_dataloader = DataLoader(test_normal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_abnormal_session, test_abnormal_dataset,test_abnormal_seq,test_abnormal_label = generate_test_data('hdfs_test_abnormal',window_size)\n",
    "abnormal_dataloader = DataLoader(test_abnormal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "test_normal_result,test_abnormal_result = fast_predict(model,normal_dataloader,abnormal_dataloader,10,window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 快速预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast predict\n",
    "def fast_predict(model,normal_dataloader,abnormal_dataloader,num_candidates=5,window_size=10):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    # Test the model\n",
    "    start_time = time.time()\n",
    "    test_normal_result = []\n",
    "    test_abnormal_result = []\n",
    "    with torch.no_grad():\n",
    "        result = []\n",
    "        with torch.no_grad():\n",
    "            for step, (seq, labels) in tqdm(enumerate(normal_dataloader), desc='normal'):\n",
    "                seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "                output = model(seq).cpu()\n",
    "\n",
    "                predicted = torch.argsort(output[:,-1,:], 1)[:,-num_candidates:]\n",
    "                for i, label in enumerate(labels):\n",
    "                    if label not in predicted[i]:\n",
    "                        test_normal_result.append(True)\n",
    "                    else:\n",
    "                        test_normal_result.append(False)\n",
    "    for session in test_normal_session:\n",
    "        for seq_id in session:\n",
    "            if test_normal_result[seq_id] == True:\n",
    "                FP += 1\n",
    "                break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (seq, labels) in tqdm(enumerate(abnormal_dataloader), desc='abnormal'):\n",
    "            seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "            output = model(seq).cpu()\n",
    "\n",
    "            predicted = torch.argsort(output[:,-1,:], 1)[:,-num_candidates:]\n",
    "            for i, label in enumerate(labels):\n",
    "                if label not in predicted[i]:\n",
    "                    test_abnormal_result.append(True)\n",
    "                else:\n",
    "                    test_abnormal_result.append(False)\n",
    "        for session in test_abnormal_session:\n",
    "            for seq_id in session:\n",
    "                if test_abnormal_result[seq_id] == True:\n",
    "                    TP += 1\n",
    "                    break\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
    "    # Compute precision, recall and F1-measure\n",
    "    FN = len(test_abnormal_session) - TP\n",
    "    P = 100 * TP / (TP + FP)\n",
    "    R = 100 * TP / (TP + FN)\n",
    "    F1 = 2 * P * R / (P + R)\n",
    "    print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
    "    print('Finished Predicting')\n",
    "    return test_normal_result,test_abnormal_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 3, 4, 3, 23, 23, 23, 21, 21, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_normal_seq[FP_result[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 26, 11, 9, 26, 23, 23, 23, 21, 21, 2)\n",
      "预测的序号排序: tensor([11, 18,  9, 23, 25,  4,  6,  5, 30, 21])\n",
      "对应的可能性: tensor([1.2008e-05, 6.2610e-05, 6.4171e-05, 1.5609e-04, 1.9687e-04, 2.1495e-04,\n",
      "        2.5744e-04, 9.2612e-04, 3.7864e-03, 9.9431e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(9, 11, 9, 11, 9, 26, 26, 25, 18, 5, 26)\n",
      "预测的序号排序: tensor([18, 30,  5, 23,  2, 21,  3,  6,  4, 16])\n",
      "对应的可能性: tensor([0.0016, 0.0018, 0.0022, 0.0074, 0.0120, 0.0610, 0.0631, 0.0851, 0.1440,\n",
      "        0.6199], grad_fn=<IndexBackward>)\n",
      "\n",
      "(4, 3, 4, 3, 3, 23, 23, 23, 21, 21, 20)\n",
      "预测的序号排序: tensor([ 2,  9, 18, 23, 25,  6,  4,  5, 30, 21])\n",
      "对应的可能性: tensor([4.0952e-06, 2.1788e-05, 3.2698e-05, 1.0069e-04, 1.0320e-04, 1.3307e-04,\n",
      "        1.8714e-04, 2.4859e-04, 1.1386e-03, 9.9802e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(5, 5, 11, 9, 26, 11, 9, 11, 9, 26, 18)\n",
      "预测的序号排序: tensor([30, 25,  9, 21,  2,  3, 23,  4, 11, 26])\n",
      "对应的可能性: tensor([5.6737e-06, 6.3830e-06, 2.5268e-05, 3.5254e-05, 6.4369e-05, 6.6575e-05,\n",
      "        1.1359e-04, 1.2045e-04, 4.4903e-04, 9.9911e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(25, 18, 5, 16, 6, 26, 26, 21, 25, 5, 18)\n",
      "预测的序号排序: tensor([26, 21,  5,  2,  3, 11, 30,  4,  6, 16])\n",
      "对应的可能性: tensor([4.2887e-04, 5.9130e-04, 6.9202e-04, 8.1189e-04, 2.6935e-03, 5.1918e-03,\n",
      "        7.4944e-03, 1.0989e-02, 1.0733e-01, 8.6321e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(26, 25, 18, 5, 16, 6, 26, 26, 26, 21, 2)\n",
      "预测的序号排序: tensor([ 6,  4,  9, 11, 23, 21, 18,  5, 30, 25])\n",
      "对应的可能性: tensor([4.1273e-04, 1.7671e-03, 2.1457e-03, 3.1278e-03, 2.1973e-02, 2.7341e-02,\n",
      "        6.4945e-02, 9.0889e-02, 1.0011e-01, 6.8714e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(22, 5, 11, 9, 11, 9, 11, 9, 26, 26, 18)\n",
      "预测的序号排序: tensor([25, 30,  9, 21,  2,  3, 23,  4, 11, 26])\n",
      "对应的可能性: tensor([1.3379e-05, 1.6427e-05, 2.2544e-05, 3.4695e-05, 7.0259e-05, 7.4684e-05,\n",
      "        9.2925e-05, 9.3777e-05, 2.2836e-04, 9.9935e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(25, 18, 5, 6, 16, 26, 26, 21, 25, 5, 18)\n",
      "预测的序号排序: tensor([ 5,  2, 26, 21, 11,  3, 30,  4,  6, 16])\n",
      "对应的可能性: tensor([0.0008, 0.0011, 0.0017, 0.0032, 0.0066, 0.0122, 0.0283, 0.0286, 0.3081,\n",
      "        0.6077], grad_fn=<IndexBackward>)\n",
      "\n",
      "(9, 26, 26, 26, 23, 23, 23, 21, 21, 21, 2)\n",
      "预测的序号排序: tensor([18, 11, 23,  4,  5, 25,  6,  9, 21, 30])\n",
      "对应的可能性: tensor([2.8927e-06, 5.1945e-06, 1.1847e-05, 1.3195e-05, 1.3551e-05, 1.7536e-05,\n",
      "        1.9130e-04, 2.2981e-04, 7.5638e-04, 9.9875e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(4, 4, 3, 3, 23, 23, 23, 21, 21, 21, 20)\n",
      "预测的序号排序: tensor([18, 11,  5, 23, 25,  4,  9,  6, 21, 30])\n",
      "对应的可能性: tensor([5.2980e-06, 6.2992e-06, 1.9546e-05, 1.9556e-05, 3.0029e-05, 3.1384e-05,\n",
      "        3.1278e-04, 3.6623e-04, 2.5055e-03, 9.9670e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(9, 26, 26, 26, 25, 18, 5, 6, 26, 16, 26)\n",
      "预测的序号排序: tensor([11,  3,  4,  5, 21,  9, 23, 30,  6, 25])\n",
      "对应的可能性: tensor([0.0034, 0.0086, 0.0120, 0.0143, 0.0475, 0.0782, 0.1032, 0.1050, 0.1467,\n",
      "        0.4751], grad_fn=<IndexBackward>)\n",
      "\n",
      "(11, 9, 5, 11, 9, 5, 11, 9, 26, 26, 22)\n",
      "预测的序号排序: tensor([25, 18, 21,  4,  9, 11,  3,  2, 23, 26])\n",
      "对应的可能性: tensor([6.3902e-04, 6.6193e-04, 1.3087e-03, 1.3233e-03, 2.9110e-03, 6.8536e-03,\n",
      "        1.5435e-02, 2.3630e-02, 1.9822e-01, 7.4898e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(18, 25, 11, 9, 11, 9, 11, 9, 26, 26, 5)\n",
      "预测的序号排序: tensor([21, 18, 11, 25, 30,  2,  3,  4, 26, 23])\n",
      "对应的可能性: tensor([2.7275e-04, 3.9181e-04, 8.4748e-04, 2.9573e-03, 5.4999e-02, 6.2348e-02,\n",
      "        6.5277e-02, 7.9950e-02, 1.2387e-01, 6.0899e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(3, 3, 3, 4, 23, 23, 23, 21, 21, 21, 20)\n",
      "预测的序号排序: tensor([18, 11,  5, 23, 25,  4,  9,  6, 21, 30])\n",
      "对应的可能性: tensor([6.8397e-06, 7.0292e-06, 2.1760e-05, 2.3963e-05, 4.0629e-05, 4.6017e-05,\n",
      "        3.7782e-04, 4.4020e-04, 3.4204e-03, 9.9561e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n",
      "(22, 11, 9, 11, 9, 26, 11, 9, 26, 25, 5)\n",
      "预测的序号排序: tensor([21, 11, 26, 18, 25,  2,  3,  4, 30, 23])\n",
      "对应的可能性: tensor([8.9138e-05, 3.0668e-04, 8.6515e-04, 1.1009e-03, 2.3865e-03, 3.6944e-02,\n",
      "        3.7691e-02, 4.2285e-02, 1.5168e-01, 7.2662e-01],\n",
      "       grad_fn=<IndexBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in FP_result[10:25]:\n",
    "    seq = test_normal_seq[i]\n",
    "    t = torch.FloatTensor(seq[:-1]).reshape(1,-1)\n",
    "    max_len = 60\n",
    "    pattern = set()\n",
    "    t,predicted,output = generate_seq(t,1,10,1)\n",
    "    prob = softmax(output)\n",
    "    print(seq)\n",
    "#     print(t.int().cpu().numpy()[0])\n",
    "    print(\"预测的序号排序:\",end=' ')\n",
    "    print(predicted)\n",
    "    print(\"对应的可能性:\",end=' ')\n",
    "    print(prob[predicted])\n",
    "    print()\n",
    "    pattern.add(tuple(t.int().cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(start,window_size=10,num_candidates=5,scope=None):\n",
    "    bg = start.size(1) \n",
    "    if scope==None:\n",
    "        scope=num_candidates\n",
    "    for i in range(bg,bg+window_size):\n",
    "#         start = torch.FloatTensor(start)\n",
    "        seq = start.clone().detach().view(-1, i, input_size).to(device)\n",
    "        output = model(seq).cpu()[:,-1,:]\n",
    "        output = output.reshape(-1)\n",
    "        predicted = torch.argsort(output)[-num_candidates:]\n",
    "        nxt = random.randint(1,scope)\n",
    "        start = torch.cat([start,predicted[-nxt].reshape(1,-1).float()],1)\n",
    "    return start,predicted,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.FloatTensor([0,5,22,5]).reshape(1,-1)\n",
    "bg = start.size(1) \n",
    "#         start = torch.FloatTensor(start)\n",
    "seq = start.clone().detach().view(-1, start.size(1), input_size).to(device)\n",
    "output = model(seq).cpu()[:,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[30, 25, 26, 11, 23, 15, 20, 12, 29,  9, 24,  8, 27,  0, 28, 14, 17,\n",
       "           7,  1, 19, 10, 13, 21, 18,  6,  2, 16, 22,  3,  4,  5],\n",
       "         [30,  6,  4, 17, 21,  3, 14, 28, 29, 27, 19,  0, 11, 24, 20,  1, 12,\n",
       "          10, 15, 16,  8, 13,  7,  9,  5, 18,  2, 23, 25, 22, 26],\n",
       "         [30, 17,  2, 14, 19, 20, 24, 28, 27, 15,  0,  8, 12,  1, 25, 10, 29,\n",
       "           7, 13, 23, 16, 21, 22, 26,  3,  6, 18,  9, 11,  5,  4],\n",
       "         [17, 14, 27, 28,  1, 24, 13, 19,  7, 15, 29, 10, 12,  8,  0, 20, 18,\n",
       "          21, 25, 30,  6,  2, 22, 23, 16,  5, 11, 26,  9,  3,  4]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(output,2)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  5.,  5., 22., 26.]])\n",
      "预测的序号排序: tensor([ 5, 26, 11])\n",
      "对应的可能性: tensor([0.0050, 0.0205, 0.9656], grad_fn=<IndexBackward>)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([0,5,5,22]).reshape(1,-1)\n",
    "t,predicted,output = generate_seq(t,1,3)\n",
    "prob = softmax(output)\n",
    "print(t)\n",
    "#     print(t.int().cpu().numpy()[0])\n",
    "print(\"预测的序号排序:\",end=' ')\n",
    "print(predicted)\n",
    "print(\"对应的可能性:\",end=' ')\n",
    "print(prob[predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  5., 18.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2192e-04, 2.4864e-01, 7.5096e-01], grad_fn=<IndexBackward>)\n"
     ]
    }
   ],
   "source": [
    "prob = softmax(output)\n",
    "print(prob[predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 5]\n",
      "预测的序号排序: tensor([18, 22,  5])\n",
      "对应的可能性: tensor([0.0009, 0.2551, 0.7420], grad_fn=<IndexBackward>)\n",
      "\n",
      "[0 5 5]\n",
      "预测的序号排序: tensor([18, 22,  5])\n",
      "对应的可能性: tensor([1.2192e-04, 2.4864e-01, 7.5096e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[0 5 5 5]\n",
      "预测的序号排序: tensor([11, 22,  5])\n",
      "对应的可能性: tensor([3.8608e-05, 3.4809e-01, 6.5181e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22]\n",
      "预测的序号排序: tensor([26,  5, 22])\n",
      "对应的可能性: tensor([0.0010, 0.0013, 0.9970], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11]\n",
      "预测的序号排序: tensor([26,  9, 11])\n",
      "对应的可能性: tensor([0.0159, 0.0212, 0.9590], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9]\n",
      "预测的序号排序: tensor([26, 11,  9])\n",
      "对应的可能性: tensor([4.3829e-04, 2.5918e-03, 9.9695e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11]\n",
      "预测的序号排序: tensor([ 9, 26, 11])\n",
      "对应的可能性: tensor([0.0077, 0.0478, 0.9439], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9]\n",
      "预测的序号排序: tensor([26, 11,  9])\n",
      "对应的可能性: tensor([5.0201e-04, 3.3620e-03, 9.9612e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11]\n",
      "预测的序号排序: tensor([ 9, 26, 11])\n",
      "对应的可能性: tensor([0.0024, 0.1226, 0.8749], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9]\n",
      "预测的序号排序: tensor([11, 26,  9])\n",
      "对应的可能性: tensor([2.7529e-04, 4.3636e-04, 9.9929e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26]\n",
      "预测的序号排序: tensor([ 2, 11, 26])\n",
      "对应的可能性: tensor([6.7779e-05, 1.3595e-04, 9.9970e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26]\n",
      "预测的序号排序: tensor([ 4, 11, 26])\n",
      "对应的可能性: tensor([1.3575e-05, 4.9616e-05, 9.9991e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26 26]\n",
      "预测的序号排序: tensor([23, 11, 26])\n",
      "对应的可能性: tensor([1.3897e-04, 3.1265e-04, 9.9909e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26 26 23]\n",
      "预测的序号排序: tensor([ 2, 30, 23])\n",
      "对应的可能性: tensor([0.0858, 0.2746, 0.4617], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26 26 23 23]\n",
      "预测的序号排序: tensor([30, 18, 23])\n",
      "对应的可能性: tensor([0.0022, 0.0028, 0.9918], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26 26 23 23 23]\n",
      "预测的序号排序: tensor([21, 18, 23])\n",
      "对应的可能性: tensor([0.0012, 0.0024, 0.9934], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26 26 23 23 23 21]\n",
      "预测的序号排序: tensor([23,  5, 21])\n",
      "对应的可能性: tensor([4.8894e-04, 1.0820e-03, 9.9797e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26 26 23 23 23 21 21]\n",
      "预测的序号排序: tensor([ 4,  5, 21])\n",
      "对应的可能性: tensor([1.2914e-04, 2.8094e-04, 9.9934e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26 26 23 23 23 21 21 21]\n",
      "预测的序号排序: tensor([ 4, 30, 21])\n",
      "对应的可能性: tensor([7.5188e-04, 5.7734e-02, 9.3912e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26 26 23 23 23 21 21 21 30]\n",
      "预测的序号排序: tensor([ 9, 21, 30])\n",
      "对应的可能性: tensor([1.6640e-04, 1.8914e-03, 9.9769e-01], grad_fn=<IndexBackward>)\n",
      "\n",
      "[ 0  5  5  5 22 11  9 11  9 11  9 26 26 26 23 23 23 21 21 21 30]\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([0]).reshape(1,-1)\n",
    "max_len = 60\n",
    "pattern = set()\n",
    "while t.size(1)<max_len:\n",
    "    t,predicted,output = generate_seq(t,1,3,1)\n",
    "    prob = softmax(output)\n",
    "    print(t.int().cpu().numpy()[0])\n",
    "    print(\"预测的序号排序:\",end=' ')\n",
    "    print(predicted)\n",
    "    print(\"对应的可能性:\",end=' ')\n",
    "    print(prob[predicted])\n",
    "    print()\n",
    "    if 30 in t[0]:\n",
    "        break\n",
    "print(t.int().cpu().numpy()[0])\n",
    "pattern.add(tuple(t.int().cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 22  5 11  9  5 26 26 26 11 11 11  9 11  9  3  4  3  4  4  4  4  3  2\n",
      "  2  2 23 23 23 21 21 21 21 21 30]\n",
      "[ 0 22 11  9  5  5 26 11  9 11 11 11 26 11  4  3  3 23  2  3  4  2 23  2\n",
      "  4  3  3  2 23  2 23 23 23  5  6 16  6  3  2 23 23 23 21  5  6 26 21 21\n",
      " 25 30]\n",
      "[ 0 22 11  9 11  9 26 26 11  9 11 26  4  4  3  2 23  2  3  2  4  3  3  3\n",
      "  4 23 23 23 21  4  6 16 26 21 25 30]\n",
      "[ 0 22  5  5 11  9 26 26 26 11  9  9  9 11 23 30]\n",
      "[ 0  5 22 11  5 11  9 11  9 11  9 26  4  4  4  4  3  4  3  4  3  4  4  4\n",
      " 23 23  5  4  3  2 23  2  4  3  4 23 23 23 21 21 30]\n",
      "[ 0 22 11  5 11 11 11  9 26 26 11  9  4  4  3  2 23 23 23 23 21 21 21 30]\n",
      "[ 0  5  5  5 22 11  9 11 11 11  9 26 26 11 26  3  4  4  4  4  4  4  3  4\n",
      "  2  2 23  2  4  4  4 23 23 23 21  5  6 16  6 26 26 30]\n",
      "[ 0 22  5  5  5 26 11 26 26 11  9  9  9 11 11  3  4  3 23 23 23 21  5 21\n",
      " 21 21 21 30]\n",
      "[ 0  5  5  5 22 11  9 26 11 11 11 11 26 11  3  4  3  2  2  2  2 23  5 16\n",
      "  6 16 26 30]\n",
      "[ 0  5 22  5  5 26 11  9 26 11 11 11  9 26 26 23 23 23  5 21 30]\n"
     ]
    }
   ],
   "source": [
    "pattern = set()\n",
    "for i in range(10):\n",
    "    t = torch.FloatTensor([0]).reshape(1,-1)\n",
    "    max_len = 60\n",
    "    while t.size(1)<max_len:\n",
    "        t,predicted,output = generate_seq(t,1,2)\n",
    "        if 30 in t[0]:\n",
    "            break\n",
    "    print(t.int().cpu().numpy()[0])\n",
    "    pattern.add(tuple(t.int().cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 10.,  8., 10.,  8.,  1.,  2.,  2.,  3.,  2.])\n",
      "tensor([[ 8.,  8., 25.,  2.,  2., 22.,  1., 22.,  1.,  1.,  3.]])\n",
      "tensor([10.,  8., 10.,  8.,  1.,  2.,  2.,  3.,  2.])\n",
      "tensor([ 8., 25.,  2.,  2., 22.,  1., 22.,  1.,  1.,  3.])\n",
      "\n",
      "tensor([10.,  8., 10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.])\n",
      "tensor([[10.,  3.,  1.,  3.,  3., 22., 22., 24., 22.,  5.,  5.]])\n",
      "tensor([ 8., 10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.])\n",
      "tensor([ 3.,  1.,  3.,  3., 22., 22., 24., 22.,  5.,  5.])\n",
      "\n",
      "tensor([ 8., 10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.,  2.])\n",
      "tensor([[ 8.,  2.,  2.,  3.,  2.,  3.,  1., 21.,  1., 22.,  2.]])\n",
      "tensor([10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.,  2.])\n",
      "tensor([ 2.,  2.,  3.,  2.,  3.,  1., 21.,  1., 22.,  2.])\n",
      "\n",
      "tensor([10.,  8.,  1.,  2.,  2.,  3.,  2.,  3.,  2.,  2.])\n",
      "tensor([[10.,  8.,  2., 22., 25., 20., 22., 30., 30., 20., 30.]])\n",
      "tensor([8., 1., 2., 2., 3., 2., 3., 2., 2.])\n",
      "tensor([ 8.,  2., 22., 25., 20., 22., 30., 30., 20., 30.])\n",
      "\n",
      "tensor([8., 1., 2., 2., 3., 2., 3., 2., 2., 2.])\n",
      "tensor([[ 8., 25., 10.,  1.,  1.,  1., 22., 22., 22., 22.,  3.]])\n",
      "tensor([1., 2., 2., 3., 2., 3., 2., 2., 2.])\n",
      "tensor([25., 10.,  1.,  1.,  1., 22., 22., 22., 22.,  3.])\n",
      "\n",
      "tensor([1., 2., 2., 3., 2., 3., 2., 2., 2., 3.])\n",
      "tensor([[ 1., 21.,  3.,  5., 15., 22., 10.,  2.,  1.,  1., 22.]])\n",
      "tensor([2., 2., 3., 2., 3., 2., 2., 2., 3.])\n",
      "tensor([21.,  3.,  5., 15., 22., 10.,  2.,  1.,  1., 22.])\n",
      "\n",
      "tensor([2., 2., 3., 2., 3., 2., 2., 2., 3., 1.])\n",
      "tensor([[ 2., 21.,  3.,  1., 22., 24., 20., 22., 20., 20., 24.]])\n",
      "tensor([2., 3., 2., 3., 2., 2., 2., 3., 1.])\n",
      "tensor([21.,  3.,  1., 22., 24., 20., 22., 20., 20., 24.])\n",
      "\n",
      "tensor([ 2.,  3.,  2.,  3.,  2.,  2.,  2.,  3.,  1., 22.])\n",
      "tensor([[ 2., 10.,  2., 10.,  1., 22., 24., 22.,  3., 15.,  5.]])\n",
      "tensor([ 3.,  2.,  3.,  2.,  2.,  2.,  3.,  1., 22.])\n",
      "tensor([10.,  2., 10.,  1., 22., 24., 22.,  3., 15.,  5.])\n",
      "\n",
      "tensor([ 3.,  2.,  3.,  2.,  2.,  2.,  3.,  1., 22., 22.])\n",
      "tensor([[ 3.,  3.,  2.,  2.,  2.,  3.,  2.,  3., 22., 22., 24.]])\n",
      "tensor([ 2.,  3.,  2.,  2.,  2.,  3.,  1., 22., 22.])\n",
      "tensor([ 3.,  2.,  2.,  2.,  3.,  2.,  3., 22., 22., 24.])\n",
      "\n",
      "tensor([ 2.,  3.,  2.,  2.,  2.,  3.,  1., 22., 22., 22.])\n",
      "tensor([[ 2.,  3.,  1.,  1.,  2.,  1., 22., 22.,  2., 20., 30.]])\n",
      "tensor([ 3.,  2.,  2.,  2.,  3.,  1., 22., 22., 22.])\n",
      "tensor([ 3.,  1.,  1.,  2.,  1., 22., 22.,  2., 20., 30.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for step, (seq, labels) in tqdm(enumerate(normal_dataloader), desc='normal'):\n",
    "        break\n",
    "for s in seq[100:110]:\n",
    "    t = s[:1].reshape(1,-1)\n",
    "    res,_ = generate_seq(t)\n",
    "    print(s)\n",
    "    print(res)\n",
    "\n",
    "    print(s[t.size(1):])\n",
    "    print(res[0,t.size(1):])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seq(candidates):\n",
    "    current_log = [0]\n",
    "    idx_list = []\n",
    "    cur = 0\n",
    "    seq = torch.FloatTensor(current_log).reshape(1,-1)\n",
    "    _,predicted,output = generate_seq(seq,1,3)\n",
    "#     predicted = torch.sort(predicted)\n",
    "    while 30!=predicted[-1]:\n",
    "        prob = softmax(output)\n",
    "        flag = True\n",
    "        for log in torch.flip(predicted,dims=[0]):\n",
    "            if prob[log]>0.2 and log in candidates[cur:]:\n",
    "                current_log.append(log.numpy().tolist())\n",
    "                cur =candidates.index(log,cur)\n",
    "#                 print(log)\n",
    "#                 print(torch.flip(predicted,dims=[0]))\n",
    "                idx_list.append(cur)\n",
    "                cur = cur+1\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            break\n",
    "        seq = torch.FloatTensor(current_log).reshape(1,-1)\n",
    "        _,predicted,output = generate_seq(seq,1,3)\n",
    "    return current_log,idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_eles_from_list(eles_list,idx_list):\n",
    "    for i in idx_list[::-1]:\n",
    "        eles_list.pop(i)\n",
    "    return eles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_seq(seq1,seq2):\n",
    "    i1 = 0\n",
    "    i2 = 0\n",
    "    seq_mess = []\n",
    "    while i1<len(seq1) and i2<len(seq2):\n",
    "        if random.randint(0,9)<5:\n",
    "            seq_mess.append(seq1[i1])\n",
    "            i1+=1\n",
    "        else:\n",
    "            seq_mess.append(seq2[i2])\n",
    "            i2+=1\n",
    "    if i1<len(seq1):\n",
    "        seq_mess.extend(seq1[i1:])\n",
    "    if i2<len(seq2):\n",
    "        seq_mess.extend(seq2[i2:])\n",
    "    return seq_mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 22, 5, 5, 5, 22, 5, 11, 5, 9, 26, 11, 26, 11, 9, 11, 9, 9, 11, 11, 9, 26, 9, 23, 23, 26, 23, 26, 21, 21, 26, 23, 23, 21, 23, 21, 21, 21]\n"
     ]
    }
   ],
   "source": [
    "seq1 = [5,5,5,22,11,9,11,9,11,9,26,26,26,23,23,23,21,21,21]\n",
    "seq2 = [22,5,5,5,26,26,11,9,11,9,11,9,26,23,23,23,21,21,21]\n",
    "seq_mess = merge_seq(seq1,seq2)\n",
    "print(seq_mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 5, 5, 22, 11, 9, 11, 9, 11, 9, 26, 26, 26, 23, 23, 23, 21, 21, 21]\n",
      "[22, 5, 5, 5, 26, 26, 11, 9, 11, 11, 9, 9, 23, 23, 23, 21, 21, 26, 21]\n"
     ]
    }
   ],
   "source": [
    "candidates = [i for i in seq_mess]\n",
    "res,idx_list = extract_seq(candidates)\n",
    "print(res)\n",
    "print(del_eles_from_list(candidates,idx_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 5, 5]\n",
      "[22, 26, 26, 11, 9, 11, 11, 9, 9, 23, 23, 23, 21, 21, 26, 21]\n"
     ]
    }
   ],
   "source": [
    "res,idx_list = extract_seq(candidates)\n",
    "print(res)\n",
    "print(del_eles_from_list(candidates,idx_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seq_v2(candidates):\n",
    "    current_log = [0,candidates[0]]\n",
    "    idx_list = [0]\n",
    "    cur = 1\n",
    "    seq = torch.FloatTensor(current_log).reshape(1,-1)\n",
    "    _,predicted,output = generate_seq(seq,1,3)\n",
    "#     predicted = torch.sort(predicted)\n",
    "    while 30!=predicted[-1]:\n",
    "        prob = softmax(output)\n",
    "        flag = True\n",
    "        for log in torch.flip(predicted,dims=[0]):\n",
    "            if prob[log]>0.2 and log in candidates[cur:]:\n",
    "                current_log.append(log.numpy().tolist())\n",
    "                cur =candidates.index(log,cur)\n",
    "#                 print(log)\n",
    "#                 print(torch.flip(predicted,dims=[0]))\n",
    "                idx_list.append(cur)\n",
    "                cur = cur+1\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            break\n",
    "        seq = torch.FloatTensor(current_log[-4:]).reshape(1,-1)\n",
    "        _,predicted,output = generate_seq(seq,1,3)\n",
    "    return current_log,idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 22, 5, 5, 5, 26, 26, 26]\n",
      "[5, 5, 22, 11, 5, 9, 11, 9, 11, 11, 9, 9, 11, 11, 9, 9, 26, 26, 26, 23, 23, 23, 23, 23, 21, 21, 21, 23, 21, 21, 21]\n"
     ]
    }
   ],
   "source": [
    "candidates = [i for i in seq_mess]\n",
    "res,idx_list = extract_seq_v2(candidates)\n",
    "print(res)\n",
    "print(del_eles_from_list(candidates,idx_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 5, 5, 26, 26, 26]\n",
      "[11, 9, 11, 9, 23, 23, 23, 23, 23, 21, 21, 21, 23, 21, 21, 21]\n"
     ]
    }
   ],
   "source": [
    "res,idx_list = extract_seq_v2(candidates)\n",
    "print(res)\n",
    "print(del_eles_from_list(candidates,idx_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 22]\n",
      "[11, 9, 11, 9, 11, 11, 9, 9, 11, 11, 9, 9, 26, 26, 26, 23, 23, 23, 23, 23, 21, 21, 21, 23, 21, 21, 21]\n"
     ]
    }
   ],
   "source": [
    "res,idx_list = extract_seq_v2(candidates)\n",
    "print(res)\n",
    "print(del_eles_from_list(candidates,idx_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([26, 11,  9])\n",
      "tensor([0.0030, 0.0069, 0.9894], grad_fn=<IndexBackward>)\n"
     ]
    }
   ],
   "source": [
    "seq = torch.FloatTensor([9,11]).reshape(1,-1)\n",
    "_,predicted,output=generate_seq(seq,1,3)\n",
    "print(predicted)\n",
    "print(softmax(output)[predicted])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 发现并发结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_concorrent(seq):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [0]\n",
    "_,predicted,output=generate_seq(seq,1,3)\n",
    "print(predicted)\n",
    "print(softmax(output)[predicted])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('cuda_pytorch': conda)",
   "language": "python",
   "name": "python36764bitcudapytorchconda3e33319a1fef4dc990a9d2f171216946"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
